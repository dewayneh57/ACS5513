# -*- coding: utf-8 -*-
"""ACS 5513 - Petabyte Pirates Project Deliverable 2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IndLhnFIcyskaO8MgSCWyfxUfZqR9HLm

# Ames Housing - Project Deliverable 2
**ACS-5513 - Applied Machine Learning**

**Dr. Neelam Dwivedi**

**Petabyte Pirates (Team A)**

**Source:** https://github.com/dewayneh57/ACS5513/blob/main/ACS-5113_Petabyte_Pirates_Deliverable_1.csv

## Initial Imports and Data Sourcing
"""

# imports
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from scipy import stats

# options
pd.set_option("display.max_columns", None)

file_path_url = 'https://raw.githubusercontent.com/dewayneh57/ACS5513/main/ACS-5113_Petabyte_Pirates_Deliverable_1.csv'

# Load the latest version
df = pd.read_csv(file_path_url)

print(df.shape)
df.head(20)

"""## Final Data Processing, Feature Engineering, and Preparation for ML Training

**Note**: while the vast majority of feature engineering was completed in Deliverable 1, there were a few outstanding changes to transform text data into numerical features. Subsequent engineering was performed to evaluate the impact of these additional features.

In result, garage finish when combined with other garage features was of high value.
"""

# encode garage finish with an ordinal map, missed from deliverable 1, and check
# pearson corelation coefficient.
# Fin    Finished (3)
# RFn    Rough Finished (2)
# Unf    Unfinished (1)
# NA    No Garage (0)

ordinal_map = {
      'Fin': 3,
      'RFn': 2,
      'Unf': 1,
      'NA': 0
  }

df['Garage Finish_Ord'] = df['Garage Finish'].map(ordinal_map).fillna(0)

correlation_garage_finish_ord = df['Garage Finish_Ord'].corr(df['SalePrice'])

print("Correlation with 'Garage Finish: ", correlation_garage_finish_ord)

# 0.56 pearson coefficient warrants evaluating multiplicatives with other
# features, such as:
#    - Garage Finish_Ord x Garage Area
#    - Garage Finish_Ord x Garage Cars
#    - Garage Finish_Ord x Garage Area x Garage Cars
# Then, with the one-hot encoded features:
#    - Garage Type__BuiltIn
#    - Garage Type__Detchd
#    - Garage Type__Other

df['Garage Finish x Garage Area'] = df['Garage Finish_Ord'] * df['Garage Area']
df['Garage Finish x Garage Cars'] = df['Garage Finish_Ord'] * df['Garage Cars']
df['Garage Finish x Garage Area x Garage Cars'] = df['Garage Finish_Ord'] * df['Garage Area'] * df['Garage Cars']

correlation_garage_finish_ord_x_garage_area = df['Garage Finish x Garage Area'].corr(df['SalePrice'])
correlation_garage_finish_ord_x_garage_cars = df['Garage Finish x Garage Cars'].corr(df['SalePrice'])
correlation_garage_finish_ord_x_garage_area_x_garage_cars = df['Garage Finish x Garage Area x Garage Cars'].corr(df['SalePrice'])

print("Correlation with 'Garage Finish x Garage Area: ", correlation_garage_finish_ord_x_garage_area)
print("Correlation with 'Garage Finish x Garage Cars: ", correlation_garage_finish_ord_x_garage_cars)
print("Correlation with 'Garage Finish x Garage Area x Garage Cars: ", correlation_garage_finish_ord_x_garage_area_x_garage_cars)

df['Garage Cars x Garage Area'] = df['Garage Cars'] * df['Garage Area']

correlation_garage_cars_x_garage_area = df['Garage Cars x Garage Area'].corr(df['SalePrice'])

print("Correlation with 'Garage Cars x Garage Area: ", correlation_garage_cars_x_garage_area)

# Also check Overall Qual x Total SF Plus Garage Correlation with SalePrice

df['Qual x SF Plus Garage'] = df['Overall Qual'] * df['Total SF Plus Garage']
df['Qual x SF Plus Garage + Garage Finish x Garage Area'] = df['Qual x SF Plus Garage'] + df['Garage Finish x Garage Area']

correlation_qual_x_sf = df['Qual x SF Plus Garage'].corr(df['SalePrice'])
correlation_qual_x_sf_garage_finish_garage_area = df['Qual x SF Plus Garage + Garage Finish x Garage Area'].corr(df['SalePrice'])

print("Correlation with 'Overall Qual x Total SF Plus Garage: ", correlation_qual_x_sf)
print("Correlation with 'Overall Qual x Total SF Plus Garage + Garage Finish x Garage Area: ", correlation_qual_x_sf_garage_finish_garage_area)

#  Clean up remaining categorical / date columns
#  and rebuild numeric model matrix
#  Columns we still need to handle:
#     BsmtFin Type 1  (nominal)
#     Garage Finish   (drop – already ordinal-encoded)
#     SaleDate        (YYYY-MM-DD)
#     Age Bucket      (ordinal buckets)
#     Season Sold     (nominal)
# ============================================================

# Drop Garage Finish (string) – we have Garage Finish_Ord
if 'Garage Finish' in df.columns:
    df.drop(columns=['Garage Finish'], inplace=True)

# Parse SaleDate and create Year / Month / Quarter numeric cols
df['SaleDate'] = pd.to_datetime(df['SaleDate'], errors='coerce')

df['SaleYear']    = df['SaleDate'].dt.year
df['SaleMonth']   = df['SaleDate'].dt.month
df['SaleQuarter'] = df['SaleDate'].dt.quarter

# Drop SaleDate
df.drop(columns=['SaleDate'], inplace=True)

# Map Age Bucket to ordered integers
age_map = {'≤10': 4, '11-30': 3, '30-60': 2, '60+': 1}
df['Age Bucket_Ord'] = df['Age Bucket'].map(age_map)
df.drop(columns=['Age Bucket'], inplace=True)

# One-hot encode BsmtFin Type 1 and Season Sold
ohe_cols = ['BsmtFin Type 1', 'Season Sold']
df = pd.get_dummies(df, columns=ohe_cols, drop_first=False, prefix_sep='__')

# Convert any lingering booleans to 0/1 ints
bool_cols = df.select_dtypes(include=['bool']).columns
df[bool_cols] = df[bool_cols].astype(int)

# At this point every column should be numeric
print(df.info())

# check all correlation with numeric features again
numeric_cols = df.select_dtypes(include=np.number).columns
corr_matrix = df[numeric_cols].corr()
corr_matrix['SalePrice'].sort_values(ascending=False).head(30)

"""## ML Model Training and Evaluation


In this section, the team began trials, beginning with an evaluation of RandomForestRegressor. This gave us an early signal of feature importance with all 107 features.

### RandomForestRegressor
"""

#  RandomForestRegressor

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score

# Modelling dataframe
df_model = df.copy()

# Drop Price per Square Feet from df_model
df_model.drop(columns=['Price per SF'], inplace=True)

X = df_model.drop('SalePrice', axis=1)
y = df_model['SalePrice']

# Train / test split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.20, random_state=42
)

# Run the RandomForestRegressor model
rf = RandomForestRegressor(
    n_estimators=400,
    max_depth=20,
    min_samples_leaf=1,
    random_state=42,
    n_jobs=-1
)
rf.fit(X_train, y_train)

# Evaluation
rmse = np.sqrt(mean_squared_error(y_test, rf.predict(X_test)))
r2   = r2_score(y_test, rf.predict(X_test))

print(f"Test RMSE : {rmse:,.0f}")
print(f"Test R²   : {r2:.3f}")

# Feature importances
imp = (
    pd.Series(rf.feature_importances_, index=X.columns)
      .sort_values(ascending=False)
)
print("\nTop-30 feature importances:")
display(imp.head(30))

# Export all feature importances to csv
imp.to_csv('feature_importances.csv')

"""### Final Data Frame for Model

The team was able to reduce the model size by 75%, from 107 features to 29, while keeping a low error margin.
"""

# Finalize the feature set and run RandomForestRegressor once more

df_model = df[[
  'Qual x SF Plus Garage + Garage Finish x Garage Area',
  'Qual x SF Plus Garage',
  'Qual x SF',
  'Remodel Age',
  'Gr Liv Area',
  'Year Remod/Add',
  'Total Bsmt SF',
  'Total SF Plus Garage',
  'Garage Yr Blt',
  'House Age',
  'Total SF',
  '1st Flr SF',
  'Fireplace Qu_Ord',
  'Year Built',
  'Kitchen Qual_Ord',
  'Garage Finish x Garage Area',
  'Garage Finish x Garage Area x Garage Cars',
  'Garage Cars x Garage Area',
  'Bsmt Qual_Ord',
  'Garage Area',
  'Heating QC_Ord',
  'Total Baths',
  'Overall Qual',
  'Full Bath',
  'Garage Finish x Garage Cars',
  'Exter Qual_Ord',
  'Garage Finish_Ord',
  'House Style__2Story',
  'Garage Cars',
  'SalePrice'
]].copy().dropna()

X = df_model.drop('SalePrice', axis=1)
y = df_model['SalePrice']

# Train / test split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.20, random_state=42
)

# Run the RandomForestRegressor model
rf = RandomForestRegressor(
    n_estimators=400,
    max_depth=20,
    min_samples_leaf=1,
    random_state=42,
    n_jobs=-1
)
rf.fit(X_train, y_train)

# Evaluation
rmse = np.sqrt(mean_squared_error(y_test, rf.predict(X_test)))
r2   = r2_score(y_test, rf.predict(X_test))

print(f"Test RMSE : {rmse:,.0f}")
print(f"Test R²   : {r2:.3f}")

# Feature importances
imp = (
    pd.Series(rf.feature_importances_, index=X.columns)
      .sort_values(ascending=False)
)
print("\nTop-30 feature importances:")
display(imp.head(30))

"""### Hyper-Parameter Tuning

The team used the RandomForestRegressor with GridSearchCV to understand the best parameters for `max_depth`, `min_samples_leaf`, and `n_estimators`.
"""

from sklearn.model_selection import GridSearchCV

param_grid = {
    'n_estimators': [100, 200, 400],
    'max_depth': [None, 10, 20],
    'min_samples_leaf': [1, 3, 5]
}

rf_base = RandomForestRegressor(random_state=42, n_jobs=-1)

grid_search = GridSearchCV(
    estimator=rf_base,
    param_grid=param_grid,
    cv=5,
    scoring='neg_root_mean_squared_error',
    n_jobs=-1,
    verbose=2
)

grid_search.fit(X, y)

# Best params and score
print(f"Best Parameters: {grid_search.best_params_}")
print(f"Best Cross-Validated RMSE: {-grid_search.best_score_:,.0f}")

"""### k-Fold Cross Validation

"""

from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import cross_val_score, KFold
from sklearn.metrics import make_scorer, mean_squared_error


# Define 5-fold CV and custom RMSE scorer
kf = KFold(n_splits=5, shuffle=True, random_state=42)

def rmse(y_true, y_pred):
    return np.sqrt(mean_squared_error(y_true, y_pred))

rmse_scorer = make_scorer(rmse, greater_is_better=False)

rf = RandomForestRegressor(
    n_estimators=400,
    max_depth=20,
    min_samples_leaf=1,
    random_state=42,
    n_jobs=-1
)

# Run CV and report results
rmse_scores = -cross_val_score(rf, X, y, cv=kf, scoring=rmse_scorer)
r2_scores   =  cross_val_score(rf, X, y, cv=kf, scoring='r2')

print(f"Cross-validated RMSE : {rmse_scores.mean():,.0f}  ± {rmse_scores.std():,.0f}")
print(f"Cross-validated R²   : {r2_scores.mean():.3f}  ± {r2_scores.std():.3f}")

# Show per-fold scores
cv_df = pd.DataFrame({
    'Fold': range(1, 6),
    'RMSE': rmse_scores.round(0),
    'R²'  : r2_scores.round(3)
})
display(cv_df)

"""### Linear Regression"""

from sklearn.linear_model import LinearRegression
from sklearn.impute import SimpleImputer
from sklearn.pipeline import Pipeline

# Impute missing values with the mean
imputer = SimpleImputer(strategy='mean')

# Create a pipeline that first imputes and then fits the Linear Regression model
lr_pipeline = Pipeline([
    ('imputer', imputer),
    ('linear_regression', LinearRegression())
])

lr_pipeline.fit(X_train, y_train)

y_pred = lr_pipeline.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

print(f"Linear Reg RMSE: {rmse:,.0f}, R²: {r2:.3f}")

### Ridge

from sklearn.linear_model import Ridge
from sklearn.impute import SimpleImputer
from sklearn.pipeline import Pipeline

# Impute missing values with the mean
imputer = SimpleImputer(strategy='mean')

# Create a pipeline that first imputes and then fits the Ridge model
ridge_pipeline = Pipeline([
    ('imputer', imputer),
    ('ridge', Ridge(alpha=10))
])

ridge_pipeline.fit(X_train, y_train)

y_pred = ridge_pipeline.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

print(f"Ridge RMSE: {rmse:,.0f}, R²: {r2:.3f}")

"""### Final Model Output and Comparison

The team folded all shortlisted models, including ensembles and stacking models, into one cell, that looped through the train, test, evaluation, and model file (pickle-based) creation.
"""

import pandas as pd, numpy as np, matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import (
    LinearRegression, Ridge, ElasticNetCV
)
from sklearn.ensemble import (
    RandomForestRegressor, HistGradientBoostingRegressor, StackingRegressor
)
from xgboost import XGBRegressor
from lightgbm import LGBMRegressor
!pip install catboost -q
from catboost import CatBoostRegressor
from joblib import dump
import warnings
from sklearn.exceptions import ConvergenceWarning

warnings.filterwarnings("ignore", category=ConvergenceWarning)
warnings.filterwarnings("ignore", message="No further splits")
warnings.filterwarnings("ignore", message="\[LightGBM\]")
warnings.filterwarnings("ignore", message="FutureWarning")

# Train / test split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.20, random_state=42
)

# Reusable imputer
imputer = SimpleImputer(strategy='mean')

# Defining the candidate models (raw)
models_raw = {
    "Random Forest": RandomForestRegressor(
        n_estimators=400, random_state=42, n_jobs=-1
    ),

    "XGBoost": XGBRegressor(
        n_estimators=400, learning_rate=0.05, max_depth=4,
        subsample=0.8, colsample_bytree=0.8, random_state=42, n_jobs=-1
    ),

    "LightGBM": LGBMRegressor(
        n_estimators=400, learning_rate=0.05, max_depth=4,
        subsample=0.8, colsample_bytree=0.8, random_state=42,
        verbosity=-1 # lots of spam to be silenced
    ),

    # Elastic-Net w/ scaling to ensure convergence
    "Elastic-NetCV": Pipeline([
        ('imputer', imputer),
        ('scaler',  StandardScaler()),
        ('enet',    ElasticNetCV(
            alphas=np.logspace(-3, 2, 50),
            l1_ratio=[.1, .5, .9],
            cv=5,
            max_iter=50000,
            tol=1e-3
        ))
    ]),

    "HistGBR": HistGradientBoostingRegressor(
        max_depth=None, learning_rate=0.05,
        max_iter=400, random_state=42
    ),

    "CatBoost": CatBoostRegressor(
        iterations=400, learning_rate=0.05,
        depth=6,loss_function='RMSE', verbose=False, random_state=42),

    "Linear Regression": LinearRegression(),

    "Ridge": Ridge(alpha=10)
}

# Wrapping the remaining models with imputer
models = {}
for name, model in models_raw.items():
    if isinstance(model, Pipeline):     # Elastic-Net already wrapped
        models[name] = model
    else:
        models[name] = Pipeline([
            ('imputer', imputer),
            (name.lower().replace(' ', '_'), model)
        ])

# Defining the stacking ensemble
stack_base = [
    ('rf',  models["Random Forest"]),
    ('xgb', models["XGBoost"]),
    ('enet', models["Elastic-NetCV"])
]

stacker = StackingRegressor(
    estimators=stack_base,
    final_estimator=Pipeline([
        ('imputer', imputer),
        ('enet_final', ElasticNetCV(cv=5, max_iter=50000))
    ]),
    passthrough=True,
    n_jobs=-1
)
models["Stacking"] = stacker

# Fit, evaluate, and export the models for our tool
results = []
for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    r2   = r2_score(y_test, y_pred)
    results.append([name, rmse, r2])

    # Save model
    dump(model, f"{name}.pkl")

results_df = (pd.DataFrame(results, columns=["Model", "RMSE", "R²"])
              .sort_values("RMSE")
              .reset_index(drop=True))
display(results_df)

# Plot on a chart
fig, ax1 = plt.subplots(figsize=(9,5))
results_df.plot(kind='bar', x='Model', y='RMSE',
                ax=ax1, color='steelblue', legend=False)
ax1.set_ylabel("RMSE")

ax2 = ax1.twinx()
results_df.plot(kind='line', x='Model', y='R²',
                ax=ax2, color='darkorange', marker='o', legend=False)
ax2.set_ylabel("R²")

ax1.set_title("Model Performance Comparison – RMSE vs R²")
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()